{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Optimization problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss\n",
    "\n",
    "- Implement a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunction:\n",
    "    \"\"\"Define a loss function to optimize.\n",
    "\n",
    "    Stored in a `ProblemDefinition`, consumed by an `Optimizer`.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, sample, pred_gradient):\n",
    "        raise NotImplementError()\n",
    "    \n",
    "    def gradient(self, sample, pred_gradient):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeastSquares(LossFunction):\n",
    "    def __call__(self, sample, pred):\n",
    "        return 0.5 * np.linalg.norm(sample - pred) ** 2\n",
    "    \n",
    "    def gradient(self, sample, pred_gradient):\n",
    "        return pred_gradient * (sample - pred_gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "- Define the function to minimize (maybe implicitly by only providing means of\n",
    "  computing the gradients)\n",
    "- Wrap the gradients computation in a friendly API\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from typing import Sequence\n",
    "\n",
    "class Problem:\n",
    "    \"\"\"Define an optimization problem.\n",
    "\n",
    "    Automatically generate helpers for gradient computation.\n",
    "    \"\"\"\n",
    "    Sample = namedtuple(\"Sample\", (\"features\", \"target\"))\n",
    "\n",
    "    def __init__(self, loss: LossFunction, samples: Sequence[Sample]):\n",
    "        self._loss = loss\n",
    "        self.samples = samples\n",
    "    \n",
    "    @property\n",
    "    def n_samples(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def full_gradient(self, state):\n",
    "        return self._loss.gradient(self.samples, state)\n",
    "    \n",
    "    def partial_gradient(self, state, index):\n",
    "        return self._loss.gradient(self.samples[index], state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator\n",
    "\n",
    "- Attempt to make predictions for a given `Problem.Sample`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estimator:\n",
    "    \"\"\"Base-class for estimators.\"\"\"    \n",
    "    def predict(self, features):\n",
    "        \"\"\"Attempt to predict a label given some features.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def update(self):\n",
    "        \"\"\"Update the estimator's parameters.\n",
    "        \n",
    "        To be called from an Optimizer.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n",
    "- Optimize a problem defined by a `ProblemDefinition`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Tuple\n",
    "\n",
    "from project.utils import LoggerMixin\n",
    "\n",
    "\n",
    "class Optimizer(LoggerMixin):\n",
    "    \"\"\"Base-class for optimizers.\"\"\"    \n",
    "    def optimize(self, problem, estimator, n_steps=1):\n",
    "        \"\"\"Run the optimizer on the current problem.\"\"\"\n",
    "        self._prepare(problem)\n",
    "        losses = []\n",
    "\n",
    "        for step, state in self.iterate(n_steps):\n",
    "            if step % 100 == 1:\n",
    "                self.logger.info(\"Step {}/{}\".format(step, n_steps))\n",
    "            losses.append(problem.loss(state))\n",
    "\n",
    "        self._cleanup()\n",
    "        return losses\n",
    "    \n",
    "    def _prepare(self, problem):\n",
    "        \"\"\"Prepare the optimizer state from the problem at hand.\n",
    "\n",
    "        Override this method in subclasses.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def _cleanup(self):\n",
    "        \"\"\"Clean the optimizer state (optional).\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def iterate(self, n_steps: int) -> Iterable[Tuple[int, dict]]:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Optimizer\n",
    "\n",
    "- Use the simple update rule $x_{t+1} = x_t - \\gamma \\, g(x_t)$ where $g$ is a\n",
    "  function to override in sub-classes\n",
    "- Default implementation uses the true gradient $g(x_t) = \\nabla f(x_t)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescent(Optimizer):\n",
    "    \"\"\"Gradient Descent algorithm.\"\"\"\n",
    "    def __init__(self, learning_rate: float, *args, **kwargs):\n",
    "        super().__init__(self, *args, **kwargs)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def get_update(self, state):\n",
    "        return self.problem.full_gradient(state)\n",
    "\n",
    "    def iterate(self, n_steps):\n",
    "        for step in range(n_steps):\n",
    "            # TODO: state - self.learning_rate * self.get_update(state)\n",
    "\n",
    "    def _prepare(self, problem):\n",
    "        self.problem = problem\n",
    "\n",
    "    def _cleanup(self):\n",
    "        del self.problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent\n",
    "\n",
    "- Define the stochastic variant of Gradient Descent,\n",
    "- Add a batch variant as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(GradientDescent):\n",
    "    \"\"\"Stochastic Gradient Descent algorithm.\"\"\"\n",
    "    def __init__(self, *args, seed=None, **kwargs):\n",
    "        self._random = np.random.RandomState(seed)\n",
    "\n",
    "    def get_update(self, state):\n",
    "        index = self._random.randint(self.problem.n_samples)\n",
    "        return self.problem.partial_gradient(state, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD with Control Variates\n",
    "\n",
    "- Define a base-class for SGD variants using control variates for correcting\n",
    "  the partial gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ControlVariatesOptimizer(SGD):\n",
    "    \"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVRG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVRG(ControlVariatesOptimizer):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hessian control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HessianCV(ControlVariatesOptimizer):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
